"use strict";(globalThis.webpackChunkgoose=globalThis.webpackChunkgoose||[]).push([[3174],{28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>a});var o=n(96540);const s={},i=o.createContext(s);function r(e){const t=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(i.Provider,{value:t},e.children)}},64940:e=>{e.exports=JSON.parse('{"permalink":"/goose/blog/2025/10/14/designing-ai-for-humans","source":"@site/blog/2025-10-14-designing-ai-for-humans/index.md","title":"Designing AI for Users, Not Just LLMs","description":"Building intent-based AI experiences with MCP-UI.","date":"2025-10-14T00:00:00.000Z","tags":[],"readingTime":4.56,"hasTruncateMarker":true,"authors":[{"name":"Ebony Louis","title":"Developer Advocate","page":{"permalink":"/goose/blog/authors/ebony"},"socials":{"linkedin":"https://www.linkedin.com/in/ebonylouis/","x":"https://x.com/ebonyjlouis","github":"https://github.com/ebonylouis"},"imageURL":"https://avatars.githubusercontent.com/u/55366651?v=4","key":"ebony"}],"frontMatter":{"title":"Designing AI for Users, Not Just LLMs","description":"Building intent-based AI experiences with MCP-UI.","authors":["ebony"]},"unlisted":false,"prevItem":{"title":"Intro to Agent Client Protocol (ACP): The Standard for AI Agent-Editor Integration","permalink":"/goose/blog/2025/10/24/intro-to-agent-client-protocol-acp"},"nextItem":{"title":"Build Your Own Recipe Cookbook Generator for goose","permalink":"/goose/blog/2025/10/08/recipe-cookbook-generator"}}')},78943:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>h,contentTitle:()=>a,default:()=>l,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var o=n(64940),s=n(74848),i=n(28453);const r={title:"Designing AI for Users, Not Just LLMs",description:"Building intent-based AI experiences with MCP-UI.",authors:["ebony"]},a=void 0,h={authorsImageUrls:[void 0]},c=[{value:"<strong>When AI Starts Showing, Not Just Talking</strong>",id:"when-ai-starts-showing-not-just-talking",level:3},{value:"<strong>Why This Matters for Builders</strong>",id:"why-this-matters-for-builders",level:3}];function d(e){const t={a:"a",blockquote:"blockquote",em:"em",h3:"h3",hr:"hr",img:"img",p:"p",strong:"strong",...(0,i.R)(),...e.components},{Head:o}=t;return o||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Designing AI For Users",src:n(94554).A+"",width:"2240",height:"1260"})}),"\n",(0,s.jsx)(t.p,{children:"My mom was doing her usual Sunday ritual she had her pen, paper, calculator, and a pile of receipts. I\u2019ve tried to get her to use every budgeting app out there, but she\u2019s old school and always says the same thing:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"\u201cThey\u2019re all too complicated.\u201d"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Last month, halfway through crunching numbers, she sighed and said,"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"\u201cI just wish I could see where my money\u2019s going.\u201d"}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["So I opened ",(0,s.jsx)(t.a,{href:"http://block.github.io/goose/docs/quickstart",children:(0,s.jsx)(t.strong,{children:"goose"})}),", added her notes, and turned on ",(0,s.jsx)(t.a,{href:"https://block.github.io/goose/docs/mcp/autovisualiser-mcp",children:(0,s.jsx)(t.strong,{children:"Auto Visualiser"})}),". In seconds, her budget became this colorful, interactive chart. She hovered over each slice, analyzing where her money was going."]}),"\n",(0,s.jsx)(t.p,{children:"Now, I'm not saying this is some groundbreaking use case. There are plenty of apps that do this. What stood out to me was how simple it felt. My mom didn\u2019t need to learn anything new or adapt to someone else\u2019s design. The visualization just appeared, and she got it immediately."}),"\n",(0,s.jsx)(t.p,{children:"It wasn\u2019t about the tech working. It was about AI finally showing up in a way that made sense to her."}),"\n",(0,s.jsx)(t.h3,{id:"when-ai-starts-showing-not-just-talking",children:(0,s.jsx)(t.strong,{children:"When AI Starts Showing, Not Just Talking"})}),"\n",(0,s.jsxs)(t.p,{children:["We\u2019ve made huge progress with agentic AI. Agents can plan, reason, and act, but they often still communicate like terminals with walls of text, and no real interaction. That\u2019s where ",(0,s.jsx)(t.a,{href:"https://mcpui.dev/guide/getting-started",children:(0,s.jsx)(t.strong,{children:"MCP-UI"})})," changes everything."]}),"\n",(0,s.jsxs)(t.p,{children:["MCP-UI gives agents a visual language ",(0,s.jsx)(t.em,{children:"and"})," a way for users to interact directly within the chat window. Before this, conversations with AI consisted of a chain of prompts and responses. Now, users can actually engage with their agent through the interface itself. A button can launch a new prompt without the user typing anything. A dropdown can run a tool call in the background. A link can open a page or resource for them instantly. Even notifications can be exchanged between this embedded UI and the host application to keep everything in sync."]}),"\n",(0,s.jsx)(t.p,{children:"This is what turns an AI chat into an interface layer. Instead of describing what it can do, the agent can present real, clickable options and respond to them in real time. That makes AI conversations feel fluid and interactive."}),"\n",(0,s.jsx)(t.p,{children:"Instead of saying, \u2018Here\u2019s your data,\u2019 your agent can show it, let you act on it, and react to what you choose."}),"\n",(0,s.jsx)(t.h3,{id:"why-this-matters-for-builders",children:(0,s.jsx)(t.strong,{children:"Why This Matters for Builders"})}),"\n",(0,s.jsx)(t.p,{children:"As developers, we often design for the model first, thinking about prompt structure or JSON formatting. But the next big step for agents is how well they can anticipate what the user wants to do and needs to see."}),"\n",(0,s.jsx)(t.p,{children:"We\u2019re already seeing this shift across the industry. Google\u2019s new AI Mode is transforming search into an intent-driven experience. Instead of sending users to links, it now shows tickets, seat maps, and purchase buttons directly in the results. The web is becoming dynamic, adapting to what users are trying to do."}),"\n",(0,s.jsxs)(t.p,{children:["MCP-UI brings that same evolution into the agent world. It extends the ",(0,s.jsx)(t.a,{href:"https://modelcontextprotocol.io/docs/getting-started/intro",children:"Model Context Protocol"})," so your MCP server can return more than just data. It can render interactive components right inside your agent's chat. Whether it\u2019s a chart, button, table, or form, the agent can display live, usable views of your service instead of describing them in text."]}),"\n",(0,s.jsx)(t.p,{children:"goose\u2019s built-in Auto Visualiser is one example of this in action, automatically turning structured output into interactive visuals using MCP-UI behind the scenes."}),"\n",(0,s.jsxs)(t.p,{children:["But the potential goes much further. When developers build their own MCP servers, they get full control over ",(0,s.jsx)(t.em,{children:"how"}),"  their data appears. They can design interfaces that reflect their brand or product style, ensuring users interacting with their API through an AI agent still get a familiar experience. Imagine a Shopify MCP server returning product listings that look like their storefront, or a Notion MCP server displaying content in its block layout inside the chat."]}),"\n",(0,s.jsx)(t.p,{children:"Both point to the same future: one where AI doesn\u2019t just reply with text, but responds with the right interface for the moment. Instead of fixed screens, we get dynamic, intent-based experiences that adapt to what the user needs in real time."}),"\n",(0,s.jsx)(t.p,{children:"That\u2019s what Agentic UX is really about: building AI that responds to what the user intends to do."}),"\n",(0,s.jsxs)(t.p,{children:["If you\u2019re building your own MCP server, start by thinking about the experience you want your users to have. Then experiment with MCP-UI and design the flow you\u2019d expect if you were the one using it. For a full walkthrough, see ",(0,s.jsx)(t.a,{href:"https://block.github.io/goose/blog/2025/09/08/turn-any-mcp-server-mcp-ui-compatible",children:"How To Make An MCP Server MCP-UI Compatible"}),"."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:"I have a feeling that next month, when my mom sits down to balance her bills, she\u2019s going to ask me:"}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"\u201cYou brought that goose thing again?\u201d"}),"\n"]}),"\n",(0,s.jsxs)(o,{children:[(0,s.jsx)("meta",{property:"og:title",content:"Designing AI for Users, Not Just LLMs"}),(0,s.jsx)("meta",{property:"og:type",content:"article"}),(0,s.jsx)("meta",{property:"og:url",content:"https://block.github.io/goose/blog/2025/10/14/designing-ai-for-humans"}),(0,s.jsx)("meta",{property:"og:description",content:"Building intent-based AI experiences with MCP-UI."}),(0,s.jsx)("meta",{property:"og:image",content:"https://block.github.io/goose/assets/images/design-ai-de5d0af69d8d21111dd271624ac7cab3.png"}),(0,s.jsx)("meta",{name:"twitter:card",content:"summary_large_image"}),(0,s.jsx)("meta",{name:"twitter:title",content:"Designing AI for Users, Not Just LLMs"}),(0,s.jsx)("meta",{name:"twitter:description",content:"Building intent-based AI experiences with MCP-UI."}),(0,s.jsx)("meta",{property:"twitter:domain",content:"block.github.io/goose"}),(0,s.jsx)("meta",{name:"twitter:image",content:"https://block.github.io/goose/assets/images/design-ai-de5d0af69d8d21111dd271624ac7cab3.png"})]})]})}function l(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},94554:(e,t,n)=>{n.d(t,{A:()=>o});const o=n.p+"assets/images/design-ai-de5d0af69d8d21111dd271624ac7cab3.png"}}]);